from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.runnables import RunnablePassthrough, ConfigurableField
from langchain_core.tools import tool
from typing import Literal
from threat_detection_score.input_sanitizer.sanitize import sanitize_input
import json, textwrap, typer

app = typer.Typer()


@app.command()
def main(
    human_message_input: str = typer.Option(
        ...,  # This indicates the option is required
        "--human-message-input",  # Specify the flag name
        "-i",  # Optional shorthand flag
        help="The input message describing the cybersecurity detection scenario.",
        callback=sanitize_input  # Use the sanitize_input function for validation
    ),
    temperature: str = typer.Option(
        0.0,  # Default value
        "--temperature",  # Specify the flag name
        help="The temperature of the LLM."
    ),
    model_name: str = typer.Option(
        "gpt-4o-mini",  # Default value
        "--model-name",  # Specify the flag name
        help="The LLM model used."
    ),
    max_retries: str = typer.Option(
        3,  # Default value
        "--max-retries",  # Specify the flag name
        help="The maximum number of retries for the LLM."
    )
):

    chat_template = ChatPromptTemplate.from_messages(
        [
            ("system", "{system_prompt}"),
            ("human", "{detection_requirement}"),
        ]
    )

    system_prompt = """You are an AI assuming the role of a cyber security threat analyst.
    Your objective is to evaluate the detection requirements and determine if there are any Active Exploit(s).

    **Input:**

    - **Detection Requirement:** A detailed description of the detection requirement, including the specific exploit, technologies, and software versions involved.

    **Output:**

    - **Yes** The input detection requirement evaluation determined Active Exploits(s).
    - **No** The input detection requirement evaluation determined Active Exploits(s).
    """

    prompt = chat_template.partial(system_prompt=system_prompt)

    model = ChatOpenAI().configurable_fields(
        temperature=ConfigurableField(
            id="llm_temperature",
            name="LLM Temperature",
            description="The temperature of the LLM"
        ),
        model_name=ConfigurableField(
            id="llm_model",
            name="LLM Model",
            description="The LLM model used",
        ),
        max_retries=ConfigurableField(
            id="llm_max_retries",
            name="LLM max retries",
            description="langchain LLM max retries",
        )
    )

    @tool
    def exploit_eval(answer: Literal["yes", "no"], reason: str) -> None:
        """exploitation evaulation"""
        pass

    tools = [exploit_eval]


    chain = (
        prompt
        | model.bind_tools(tools, tool_choice="exploit_eval")
    ).with_config(configurable={"llm_temperature": temperature, "llm_model": model_name, "llm_max_retries": max_retries})


    llm_result = chain.invoke({"detection_requirement": human_message_input})

    answer = llm_result.tool_calls[0]["args"]["answer"]
    reason = llm_result.tool_calls[0]["args"]["reason"]

    result = {
    "answer": answer,
    "reason": "\n".join(textwrap.wrap(reason, width=80)),
    "type": "exploit_eval"
    }

    print(json.dumps(result))

if __name__ == "__main__":
    app()
